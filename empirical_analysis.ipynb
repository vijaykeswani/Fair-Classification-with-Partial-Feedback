{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import warnings\n",
    "import numpy as np\n",
    "import itertools as iter\n",
    "from copy import deepcopy\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# silent warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "rng = np.random.default_rng(1234)\n",
    "random.seed()\n",
    "\n",
    "from utils import *\n",
    "from algorithms import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch dataset - either Adult Income or German Credit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Specify dataset - choose either \"adult\" or \"german\" - and protected attribute - \"race\" or \"gender\" \n",
    "## For German, we only use \"gender\" as protected attribute\n",
    "\n",
    "dataset = \"adult\"\n",
    "protected_attribute = \"race\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset == \"adult\":\n",
    "    dataset_all, PROT_GRP_INDEX = get_adult_dataset(protected_attribute)\n",
    "elif dataset == \"german\":\n",
    "    dataset_all, PROT_GRP_INDEX = get_german_dataset()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify parameters for the algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FDR constraint parameter\n",
    "ALPHA = 0.15\n",
    "\n",
    "# initial exploit FDR parameter\n",
    "EXPLOIT_ALPHA = 0.075\n",
    "\n",
    "# initial explore FDR parameter\n",
    "EXPLORE_ALPHA = ALPHA - EXPLOIT_ALPHA\n",
    "\n",
    "# total number of online iterations\n",
    "ITERS = 40\n",
    "\n",
    "# total number of repetitions using random dataset splits\n",
    "reps = 50\n",
    "\n",
    "# whether results for each iteration should be printed or not\n",
    "verbose = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = dataset_all[0], dataset_all[1]\n",
    "# X = np.hstack((X, np.ones((len(X),1))))\n",
    "\n",
    "target_clf = get_rev_max_classifier([X, y], np.ones(len(dataset_all[0][1])), ALPHA, True, PROT_GRP_INDEX, C=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execute our algorithm and baselines using above parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_explore_exploit_all_variants(data_l, data_s, initial_clf_cons, PROT_GRP_INDEX):\n",
    "    sample_weights = np.ones(len(data_s[0][1]))\n",
    "    \n",
    "    ## Our explore-exploit algorithm\n",
    "    exp_exp = Exp_Exp_Algorithm(exploit_eps = EXPLOIT_ALPHA, explore_eps = EXPLORE_ALPHA,\n",
    "                               data_l = data_l,\n",
    "                               clf_f = initial_clf_cons)\n",
    "    \n",
    "    results = [[] for _ in range(7)]\n",
    "\n",
    "    explore_eps = EXPLORE_ALPHA\n",
    "    exploit_eps = EXPLOIT_ALPHA\n",
    "    fdr_exp = []\n",
    "\n",
    "    def execute_variant(exp_exp, data_l, data_s, results, i, exploit_eps, explore_eps, PROT_GRP_INDEX, exploit_fair, explore_fair):\n",
    "        if verbose:\n",
    "            print (\"-------------\")\n",
    "            print (\"Executing variant with exploit_fairness = \" + str(exploit_fair) + \" and exploire_fairness = \" + str(explore_fair))\n",
    "            \n",
    "        for t in (range(1,ITERS)):\n",
    "            a = exp_exp\n",
    "            X_t = data_s[t][0]\n",
    "            y_t = data_s[t][1]\n",
    "\n",
    "            preds, weights, explore_indices = a._predict(X_t, y_t, PROT_GRP_INDEX, exploit_eps, explore_eps, exploit_fair=exploit_fair, explore_fair=explore_fair)\n",
    "\n",
    "            a._update_datasets(preds, data_s[t], weights)\n",
    "            stats = get_stats(preds, data_s[t], PROT_GRP_INDEX)\n",
    "            fdr_inc = max(EXPLOIT_ALPHA + EXPLORE_ALPHA - stats['fdr'], 0)\n",
    "            exploit_eps = EXPLOIT_ALPHA * (t**0.2) # +fdr_inc\n",
    "            explore_eps = max(0, ALPHA - exploit_eps)\n",
    "\n",
    "            results[i].append(get_stats(preds, data_s[t], PROT_GRP_INDEX))        \n",
    "            if verbose:\n",
    "                print(f\"Iteration {t}\")\n",
    "                print (\"FDR\", results[i][-1][\"fdr\"])\n",
    "                print (\"Revenue\", results[i][-1][\"revenue\"])\n",
    "                print (\"Statistical rate\", results[i][-1][\"stat_rate\"])\n",
    "                print (\"Group-0 TPR\", results[i][-1][\"tp-0\"])\n",
    "                print (\"Group-1 TPR\", results[i][-1][\"tp-1\"], \"\\n\")\n",
    "                \n",
    "    \n",
    "    ## No fairness constraint\n",
    "    execute_variant(exp_exp, data_l, data_s, results, 0, exploit_eps, explore_eps, PROT_GRP_INDEX, False, False)\n",
    "    \n",
    "    ## Only exploit fairness constraint\n",
    "    execute_variant(exp_exp, data_l, data_s, results, 1, exploit_eps, explore_eps, PROT_GRP_INDEX, True, False)\n",
    "    \n",
    "    ## Only explore fairness constraint\n",
    "    execute_variant(exp_exp, data_l, data_s, results, 2, exploit_eps, explore_eps, PROT_GRP_INDEX, False, True)\n",
    "    \n",
    "    ## Both explore and exploit fairness constraint\n",
    "    execute_variant(exp_exp, data_l, data_s, results, 3, exploit_eps, explore_eps, PROT_GRP_INDEX, True, True)\n",
    "    \n",
    "    ## Baselines\n",
    "    ## Only-exploit algorithm with no exploration - FAIR_CLF\n",
    "    no_exp_fair = No_Exploration_Fair_Algorithm(eps = ALPHA,\\\n",
    "                               data_l = data_l,\n",
    "                               clf_f = initial_clf_cons)\n",
    "\n",
    "\n",
    "    ## OPT-OFFLINE baseline\n",
    "#     target_clf = get_rev_max_classifier(data_s[0], sample_weights, ALPHA+0.01, True, PROT_GRP_INDEX, C=0)\n",
    "    target = Target(eps = ALPHA,\\\n",
    "                               data_l = data_l,\n",
    "                               clf_f = target_clf)\n",
    "        \n",
    "    def execute_baseline(algo, data_l, data_s, results, i, PROT_GRP_INDEX):\n",
    "        if verbose:\n",
    "            print (\"-------------\")\n",
    "            print (\"Executing baseline\", algo._name)\n",
    "        for t in (range(1,ITERS)):\n",
    "            a = algo\n",
    "            X_t = data_s[t][0]\n",
    "            y_t = data_s[t][1]\n",
    "\n",
    "            preds, weights, frac_exp = a._predict(X = X_t, eps = ALPHA, PROT_GRP_INDEX = PROT_GRP_INDEX)\n",
    "            a._update_datasets(preds, data_s[t], weights)\n",
    "\n",
    "            results[i].append(get_stats(preds, data_s[t], PROT_GRP_INDEX))        \n",
    "\n",
    "            if verbose:\n",
    "                print(f\"Iteration {t}\")\n",
    "                print (\"FDR\", results[i][-1][\"fdr\"])\n",
    "                print (\"Revenue\", results[i][-1][\"revenue\"])\n",
    "                print (\"Statistical rate\", results[i][-1][\"stat_rate\"])\n",
    "                print (\"Group-0 TPR\", results[i][-1][\"tp-0\"])\n",
    "                print (\"Group-1 TPR\", results[i][-1][\"tp-1\"], \"\\n\")\n",
    "\n",
    "\n",
    "    ## OPT-OFFLINE\n",
    "    execute_baseline(target, data_l, data_s, results, 4, PROT_GRP_INDEX)\n",
    "    \n",
    "    ## FAIR-CLF\n",
    "#     execute_baseline(no_exp_fair, data_l, data_s, results, 5, PROT_GRP_INDEX)\n",
    "        \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rep 0\n",
      "rep 1\n",
      "rep 2\n",
      "rep 3\n",
      "rep 4\n",
      "rep 5\n",
      "rep 6\n",
      "rep 7\n",
      "rep 8\n",
      "rep 9\n",
      "rep 10\n",
      "rep 11\n",
      "rep 12\n",
      "rep 13\n",
      "rep 14\n",
      "rep 15\n",
      "rep 16\n",
      "rep 17\n",
      "rep 18\n",
      "rep 19\n",
      "rep 20\n",
      "rep 21\n",
      "rep 22\n",
      "rep 23\n",
      "rep 24\n",
      "rep 25\n",
      "rep 26\n",
      "rep 27\n",
      "rep 28\n",
      "rep 29\n",
      "rep 30\n",
      "rep 31\n",
      "rep 32\n",
      "rep 33\n",
      "rep 34\n",
      "rep 35\n",
      "rep 36\n",
      "rep 37\n",
      "rep 38\n",
      "rep 39\n",
      "rep 40\n",
      "rep 41\n",
      "rep 42\n",
      "rep 43\n",
      "rep 44\n",
      "rep 45\n",
      "rep 46\n",
      "rep 47\n",
      "rep 48\n",
      "rep 49\n"
     ]
    }
   ],
   "source": [
    "results_all = []\n",
    "\n",
    "for r in (range(reps)):\n",
    "    print (\"rep\", r)\n",
    "    \n",
    "    if dataset == \"adult\":\n",
    "        data_l, data_s, initial_clf = get_adult_data_splits_and_initial_clf(dataset_all, ITERS)        \n",
    "    elif dataset == \"german\":\n",
    "        data_l, data_s, initial_clf = get_german_data_splits_and_initial_clf(dataset_all, ITERS)        \n",
    "\n",
    "    results = execute_explore_exploit_all_variants(data_l, data_s, initial_clf, PROT_GRP_INDEX)\n",
    "    results_all.append(list(results))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rep 0\n",
      "rep 1\n",
      "rep 2\n",
      "rep 3\n",
      "rep 4\n",
      "rep 5\n",
      "rep 6\n",
      "rep 7\n",
      "rep 8\n",
      "rep 9\n",
      "rep 10\n",
      "rep 11\n",
      "rep 12\n",
      "rep 13\n",
      "rep 14\n",
      "rep 15\n",
      "rep 16\n",
      "rep 17\n",
      "rep 18\n",
      "rep 19\n",
      "rep 20\n",
      "rep 21\n",
      "rep 22\n",
      "rep 23\n",
      "rep 24\n",
      "rep 25\n",
      "rep 26\n",
      "rep 27\n",
      "rep 28\n",
      "rep 29\n",
      "rep 30\n",
      "rep 31\n",
      "rep 32\n",
      "rep 33\n",
      "rep 34\n",
      "rep 35\n",
      "rep 36\n",
      "rep 37\n",
      "rep 38\n",
      "rep 39\n",
      "rep 40\n",
      "rep 41\n",
      "rep 42\n",
      "rep 43\n",
      "rep 44\n",
      "rep 45\n",
      "rep 46\n",
      "rep 47\n",
      "rep 48\n",
      "rep 49\n"
     ]
    }
   ],
   "source": [
    "results_all_2 = []\n",
    "\n",
    "for r in (range(reps)):\n",
    "    print (\"rep\", r)\n",
    "    \n",
    "    if dataset == \"adult\":\n",
    "        data_l, data_s, initial_clf = get_adult_data_splits_and_initial_clf(dataset_all, ITERS)        \n",
    "    elif dataset == \"german\":\n",
    "        data_l, data_s, initial_clf = get_german_data_splits_and_initial_clf(dataset_all, ITERS)        \n",
    "\n",
    "    results = execute_explore_exploit_all_variants(data_l, data_s, initial_clf, PROT_GRP_INDEX)\n",
    "    results_all_2.append(list(results))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot results for all variants of our algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "legend = [\"Algorithm 1 w/ no fairness constraints\", \"Algorithm 1 w/ exploit fairness\", \"Algorithm 1 w/ explore fairness\", \"Algorithm 1 w/ both exploit & explore fairness\"]\n",
    "\n",
    "ITERS = 40\n",
    "plt.figure(figsize=(21,3))\n",
    "\n",
    "plt.subplot(131)\n",
    "def plot_y(dat, k, key, kl):\n",
    "    ys = [np.mean([dat[i][k][j][key] for i in range(len(dat))]) for j in range(ITERS-1)]\n",
    "    err = [np.std([dat[i][k][j][key] for i in range(len(dat))]) for j in range(ITERS-1)]\n",
    "    plt.errorbar(range(1, ITERS), ys, yerr=err, fmt=\"-o\", label=legend[kl])\n",
    "\n",
    "key = \"revenue\"\n",
    "plot_y(results_all, 0, key, 0)\n",
    "plot_y(results_all, 1, key, 1)\n",
    "plot_y(results_all, 2, key, 2)\n",
    "plot_y(results_all, 3, key, 3)\n",
    "plot_y(results_all_2, 4, key, 3)\n",
    "    \n",
    "plt.xlabel(\"Iteration\", fontsize=15)\n",
    "plt.ylabel(\"TPR for Black Applicants\", fontsize=14)\n",
    "# plt.ylim([0, 0.6])\n",
    "\n",
    "plt.subplot(132)\n",
    "key = \"fdr\"\n",
    "plot_y(results_all, 0, key, 0)\n",
    "plot_y(results_all, 1, key, 1)\n",
    "plot_y(results_all, 2, key, 2)\n",
    "plot_y(results_all, 3, key, 3)\n",
    "plot_y(results_all, 4, key, 3)\n",
    "    \n",
    "plt.xlabel(\"Iteration\", fontsize=15)\n",
    "plt.ylabel(\"TPR for White Applicants\", fontsize=14)\n",
    "# plt.ylim([0, 0.6])\n",
    "\n",
    "\n",
    "plt.subplot(133)\n",
    "def get_sr(dat):\n",
    "    return abs(dat['stat_rate'])\n",
    "\n",
    "def plot_sr(dat, k, kl):\n",
    "    ys = [np.mean([get_sr(dat[i][k][j])  for i in range(len(results_all))]) for j in range(ITERS-1)]\n",
    "    err = [np.std([get_sr(dat[i][k][j]) for i in range(len(results_all))]) for j in range(ITERS-1)]\n",
    "    plt.errorbar(range(1, ITERS), ys, yerr=err, fmt=\"-o\", label=legend[kl])\n",
    "\n",
    "plot_sr(results_all, 0, 0)\n",
    "plot_sr(results_all, 1, 1)\n",
    "plot_sr(results_all, 2, 2)\n",
    "plot_sr(results_all, 3, 3)\n",
    "\n",
    "plt.xlabel(\"Iteration\", fontsize=15)\n",
    "plt.ylabel(\"Acceptance rate\\n disparity across groups\", fontsize=14)\n",
    "# plt.ylim([0, 0.16])\n",
    "\n",
    "plt.legend(ncol=4, bbox_to_anchor=(1.05, 1.25), fontsize=14, columnspacing=0.8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm~\\ref{alg:main_algorithm} - no fairness constraint  & 70.6 (13.1)  & 0.15 (0.02)  & 0.02 (0.02)  & 0.09 (0.06) \\\\ \n",
      "Algorithm~\\ref{alg:main_algorithm} - only exploit fairness  & 71.9 (12.9)  & 0.15 (0.02)  & 0.02 (0.01)  & 0.08 (0.05) \\\\ \n",
      "Algorithm~\\ref{alg:main_algorithm} - only explore fairness  & 73.8 (13.0)  & 0.14 (0.02)  & 0.03 (0.02)  & 0.07 (0.05) \\\\ \n",
      "Algorithm~\\ref{alg:main_algorithm} - both fairness constraints  & 73.1 (13.0)  & 0.14 (0.02)  & 0.01 (0.01)  & 0.06 (0.04) \\\\ \n",
      "Baseline - \\textsc{Opt-offline}  & 72.2 (10.5)  & 0.16 (0.02)  & 0.05 (0.03)  & 0.16 (0.1) \\\\ \n"
     ]
    }
   ],
   "source": [
    "# [np.mean([data_all[i][j][0]['revenue'] for i in range(len(data_all))]) for j in range(ITERS-1)]\n",
    "# data_all[0][0][0], sum(data_s[0][0][:,PROT_GRP_INDEX])\n",
    "\n",
    "\n",
    "def pres(k, lab, keys):\n",
    "    res = lab + \" \"\n",
    "    for key in keys:\n",
    "        if key == \"total_loans\":\n",
    "            ms = np.mean([[abs(results_all[i][k][j][key])/len(data_s[0][1]) for i in range(len(results_all))] for j in range(ITERS-1)])\n",
    "            ss = np.std([[abs(results_all[i][k][j][key])/len(data_s[0][1]) for i in range(len(results_all))] for j in range(ITERS-1)])            \n",
    "            res += \" & \" + str(np.round(ms, 2)) + \" (\" + str(np.round(ss, 2)) + \") \"\n",
    "            \n",
    "        elif key == \"revenue\":\n",
    "            ms = np.mean([[abs(results_all[i][k][j][key])/1000 for i in range(len(results_all))] for j in range(ITERS-1)])\n",
    "            ss = np.std([[abs(results_all[i][k][j][key])/1000 for i in range(len(results_all))] for j in range(ITERS-1)])                        \n",
    "            res += \" & \" + str(np.round(ms, 1)) + \" (\" + str(np.round(ss, 1)) + \") \"\n",
    "            \n",
    "        else:\n",
    "            ms = np.mean([[abs(results_all[i][k][j][key]) for i in range(len(results_all))] for j in range(ITERS-1)])\n",
    "            ss = np.std([[abs(results_all[i][k][j][key]) for i in range(len(results_all))] for j in range(ITERS-1)])\n",
    "            res += \" & \" + str(np.round(ms, 2)) + \" (\" + str(np.round(ss, 2)) + \") \"\n",
    "        \n",
    "    res += \"\\\\\\ \"\n",
    "    print (res)\n",
    "    \n",
    "keys = [\"revenue\", \"fdr\", \"stat_rate\", \"tp_rate\"]\n",
    "labs = [\"Algorithm~\\\\ref{alg:main_algorithm} - no fairness constraint\", \n",
    "        \"Algorithm~\\\\ref{alg:main_algorithm} - only exploit fairness\", \n",
    "        \"Algorithm~\\\\ref{alg:main_algorithm} - only explore fairness\", \n",
    "        \"Algorithm~\\\\ref{alg:main_algorithm} - both fairness constraints\",\n",
    "        \"Baseline - \\\\textsc{Opt-offline}\"] \n",
    "#         \"Baseline - \\\\textsc{Fair-clf}\"]\n",
    "\n",
    "for i, lab in enumerate(labs):\n",
    "    pres(i, lab, keys) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "legend = [\"Algorithm 1 w/ no fairness constraints\", \"Algorithm 1 w/ exploit fairness\", \"Algorithm 1 w/ explore fairness\", \"Algorithm 1 w/ both exploit & explore fairness\", \"OPT-OFFLINE\"]\n",
    "\n",
    "ITERS = 40\n",
    "plt.figure(figsize=(21,3))\n",
    "\n",
    "plt.subplot(131)\n",
    "def plot_y(dat, k, key, kl):\n",
    "    ys = [np.mean([(dat[i][k][j][key]) for i in range(len(dat))]) for j in range(ITERS-1)]\n",
    "    err = [np.std([(dat[i][k][j][key]) for i in range(len(dat))]) for j in range(ITERS-1)]\n",
    "    plt.errorbar(range(2, ITERS), ys[1:], yerr=err[1:], fmt=\"-o\", label=legend[kl])\n",
    "\n",
    "key = \"fdr\"\n",
    "plot_y(results_all, 0, key, 0)\n",
    "plot_y(results_all, 1, key, 1)\n",
    "plot_y(results_all, 2, key, 2)\n",
    "plot_y(results_all, 3, key, 3)\n",
    "plot_y(results_all_2, 4, key, 4)\n",
    "plt.legend(ncol=1, bbox_to_anchor=(1.05, 1.75), fontsize=14, columnspacing=0.8)\n",
    "plt.xlabel(\"Iterations\", fontsize=15)\n",
    "plt.ylabel(\"Log revenue\", fontsize=15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
